{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d718b5",
   "metadata": {},
   "source": [
    "<h1>African American Vernacular English Toxicity vs. Standard English Dictionary Toxicity</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96727f85",
   "metadata": {},
   "source": [
    "In this notebook, I will use the Perspectives API using Google Cloud to test the Perspectives model for biases. Specifically, I want to test this hypothesis:\n",
    "\n",
    "The Perspective API is less effective at identifying forms of toxicity that do not contain explicit language or common swear words so there will be a lower true positive rate for detecting toxic statements because context may play a bigger role.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0bcacc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (2.125.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-api-python-client) (2.29.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-api-python-client) (2.18.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.23.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tanushkaushik/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a8013",
   "metadata": {},
   "source": [
    "<h3>In this cell, I start the API client with the API key I got from my Google Cloud account. I then create a  definition for getting toxicity (intuitively called getToxicity). The definition just connects the API (call) to the testing phrase. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9bc6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "import json\n",
    "\n",
    "API_KEY = 'AIzaSyDmXOHBwxWRcy2wO-D91_ZRIvGp3H-_ef8'\n",
    "\n",
    "client = discovery.build(\n",
    "  \"commentanalyzer\",\n",
    "  \"v1alpha1\",\n",
    "  developerKey=API_KEY,\n",
    "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "  static_discovery=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e44f01c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getToxicity(phrase):\n",
    "  analyze_request = {\n",
    "    'comment': { 'text': f'{phrase}' },\n",
    "    'requestedAttributes': {'TOXICITY': {}},\n",
    "      'languages': [\"en\"]\n",
    "  }\n",
    "  jsonResponse = client.comments().analyze(body=analyze_request).execute()\n",
    "  \n",
    "  val = float(jsonResponse['attributeScores']['TOXICITY']['summaryScore']['value'])\n",
    "  \n",
    "  if val < 0.5:\n",
    "        toxicResult = \"Non-Toxic\"\n",
    "  elif val > 0.5:\n",
    "        toxicResult = \"Toxic\"\n",
    "  else:\n",
    "        toxicResult = \"Inconclusive\"\n",
    "  \n",
    "  return f\"[{phrase}] \" + str(val) + \" \" + toxicResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc7270",
   "metadata": {},
   "source": [
    "<h3> In this cell, I use various queries developed from AAVE and SAE dictionaries to naturally be examined by the Perspectives API model. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4396b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[What's good?] 0.019603057 Non-Toxic\n",
      "[How are you?] 0.018849092 Non-Toxic\n",
      "\n",
      "\n",
      "[Yo fit is fire!] 0.24603334 Non-Toxic\n",
      "[Your outfit looks great!] 0.042657252 Non-Toxic\n",
      "\n",
      "\n",
      "[Nah, that ain't it.] 0.012691722 Non-Toxic\n",
      "[I disagree, that's not correct.] 0.021196328 Non-Toxic\n",
      "\n",
      "\n",
      "[For real? That's wild.] 0.10739898 Non-Toxic\n",
      "[Really? That's surprising.] 0.0126288915 Non-Toxic\n",
      "\n",
      "\n",
      "[Bet, I'm down.] 0.028031485 Non-Toxic\n",
      "[Sure, I agree.] 0.008544922 Non-Toxic\n",
      "\n",
      "\n",
      "[You trippin'.] 0.19986437 Non-Toxic\n",
      "[You're overreacting.] 0.09828771 Non-Toxic\n",
      "\n",
      "\n",
      "[Good lookin' out.] 0.018095128 Non-Toxic\n",
      "[Thank you for your help.] 0.010995304 Non-Toxic\n",
      "\n",
      "\n",
      "[That's a breeze.] 0.03592727 Non-Toxic\n",
      "[That's very easy.] 0.016712861 Non-Toxic\n",
      "\n",
      "\n",
      "[That's top-tier.] 0.018849092 Non-Toxic\n",
      "[That's of high quality.] 0.016838523 Non-Toxic\n",
      "\n",
      "\n",
      "[You cappin'.] 0.14429577 Non-Toxic\n",
      "[I don't believe you.] 0.19939905 Non-Toxic\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(getToxicity(\"What's good?\"))  # Greetings, AAVE\n",
    "print(getToxicity(\"How are you?\"))  # Greetings, SAE\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"Yo fit is fire!\"))  # Compliment, AAVE\n",
    "print(getToxicity(\"Your outfit looks great!\"))  # Compliment, SAE\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"Nah, that ain't it.\"))  # Disagreement, AAVE\n",
    "print(getToxicity(\"I disagree, that's not correct.\"))  # Disagreement, SAE\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"For real? That's wild.\"))  # Surprise, AAVE\n",
    "print(getToxicity(\"Really? That's surprising.\"))  # Surprise, SAE\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"Bet, I'm down.\"))  # Affirmation, AAVE\n",
    "print(getToxicity(\"Sure, I agree.\"))  # Affirmation, SAE\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"You trippin'.\"))  # Displeasure, AAVE\n",
    "print(getToxicity(\"You're overreacting.\"))  # Displeasure, SAE\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"Good lookin' out.\"))  # Appreciation, AAVE\n",
    "print(getToxicity(\"Thank you for your help.\"))  # Appreciation, SAE\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"That's a breeze.\"))  # Easy Task, AAVE\n",
    "print(getToxicity(\"That's very easy.\"))  # Easy Task, SAE\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"That's top-tier.\"))  # High Quality, AAVE\n",
    "print(getToxicity(\"That's of high quality.\"))  # High Quality, SAE\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"You cappin'.\"))  # Disbelief, AAVE\n",
    "print(getToxicity(\"I don't believe you.\"))  # Disbelief, SAE\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92dbc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[That's the jam right there!] 0.05205809 Non-Toxic\n",
      "[That song is fantastic!] 0.023671126 Non-Toxic\n",
      "\n",
      "\n",
      "[We out here thriving!] 0.031213367 Non-Toxic\n",
      "[We are succeeding in our endeavors!] 0.025556687 Non-Toxic\n",
      "\n",
      "\n",
      "[She stay winning.] 0.01426248 Non-Toxic\n",
      "[She continues to succeed.] 0.01859777 Non-Toxic\n",
      "\n",
      "\n",
      "[They're keeping it real.] 0.015644746 Non-Toxic\n",
      "[They are being authentic.] 0.022139108 Non-Toxic\n",
      "\n",
      "\n",
      "[That's on point!] 0.010429831 Non-Toxic\n",
      "[That's exactly right!] 0.011372286 Non-Toxic\n",
      "\n",
      "\n",
      "[Killing it with those moves!] 0.4402136 Non-Toxic\n",
      "[Your dance is incredibly impressive!] 0.023317585 Non-Toxic\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(getToxicity(\"That's the jam right there!\"))  # AAVE Positive\n",
    "print(getToxicity('That song is fantastic!'))  # SAE Positive\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('We out here thriving!'))  # AAVE Positive\n",
    "print(getToxicity('We are succeeding in our endeavors!'))  # SAE Positive\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('She stay winning.'))  # AAVE Positive\n",
    "print(getToxicity('She continues to succeed.'))  # SAE Positive\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"They're keeping it real.\"))  # AAVE Positive\n",
    "print(getToxicity('They are being authentic.'))  # SAE Positive\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"That's on point!\"))  # AAVE Positive\n",
    "print(getToxicity(\"That's exactly right!\"))  # SAE Positive\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Killing it with those moves!'))  # AAVE Positive\n",
    "print(getToxicity('Your dance is incredibly impressive!'))  # SAE Positive\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeae39c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Don’t be throwing shade.] 0.05205809 Non-Toxic\n",
      "[Do not make disparaging remarks.] 0.10783285 Non-Toxic\n",
      "\n",
      "\n",
      "[Stop frontin.] 0.055274166 Non-Toxic\n",
      "[Please stop pretending.] 0.1182615 Non-Toxic\n",
      "\n",
      "\n",
      "[Why you gotta be salty?] 0.16043124 Non-Toxic\n",
      "[Why are you being bitter?] 0.10175867 Non-Toxic\n",
      "\n",
      "\n",
      "[They always flexing for no reason.] 0.04760506 Non-Toxic\n",
      "[They always show off unnecessarily.] 0.034984488 Non-Toxic\n",
      "\n",
      "\n",
      "[You're doing the most right now.] 0.023553278 Non-Toxic\n",
      "[You're overdoing it at the moment.] 0.031213367 Non-Toxic\n",
      "\n",
      "\n",
      "[Bruh, you wildin’.] 0.051068526 Non-Toxic\n",
      "[You are acting irrationally.] 0.28087774 Non-Toxic\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(getToxicity('Don’t be throwing shade.'))  # AAVE Negative\n",
    "print(getToxicity('Do not make disparaging remarks.'))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"Stop frontin.\"))  # AAVE Negative\n",
    "print(getToxicity('Please stop pretending.'))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Why you gotta be salty?'))  # AAVE Negative\n",
    "print(getToxicity('Why are you being bitter?'))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('They always flexing for no reason.'))  # AAVE Negative\n",
    "print(getToxicity('They always show off unnecessarily.'))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"You're doing the most right now.\"))  # AAVE Negative\n",
    "print(getToxicity(\"You're overdoing it at the moment.\"))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Bruh, you wildin’.'))  # AAVE Negative\n",
    "print(getToxicity('You are acting irrationally.'))  # SAE Negative\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d532b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Don't be throwing shade.] 0.06421452 Non-Toxic\n",
      "[Do not make disparaging remarks.] 0.10783285 Non-Toxic\n",
      "\n",
      "\n",
      "[Stop frontin.] 0.055274166 Non-Toxic\n",
      "[Please stop pretending.] 0.1182615 Non-Toxic\n",
      "\n",
      "\n",
      "[Why you gotta be salty?] 0.16043124 Non-Toxic\n",
      "[Why are you being bitter?] 0.10175867 Non-Toxic\n",
      "\n",
      "\n",
      "[They always flexing for no reason.] 0.04760506 Non-Toxic\n",
      "[They always show off unnecessarily.] 0.034984488 Non-Toxic\n",
      "\n",
      "\n",
      "[You're doing the most right now.] 0.023553278 Non-Toxic\n",
      "[You're overdoing it at the moment.] 0.031213367 Non-Toxic\n",
      "\n",
      "\n",
      "[Bruh, you wildin'.] 0.04785245 Non-Toxic\n",
      "[You are acting irrationally.] 0.28087774 Non-Toxic\n",
      "\n",
      "\n",
      "[Well, don’t let your mouth start nothing that your ass can’t stand.] 0.8299589 Toxic\n",
      "[Don't start a fight you can't finish. ] 0.07054565 Non-Toxic\n",
      "\n",
      "\n",
      "[Ain’t no woman got no business floatin’ around without no man.] 0.16043124 Non-Toxic\n",
      "[A woman should be in a relationship with a man. ] 0.3389984 Non-Toxic\n",
      "\n",
      "\n",
      "[That's straight trash] 0.6289369 Toxic\n",
      "[That is completely unacceptable.] 0.041915078 Non-Toxic\n"
     ]
    }
   ],
   "source": [
    "# I randomly sampled AAVE Negative phrases, for which all of them came out as less than the threshold of 0.5. This \n",
    "# model is also experiencing word bias — whenever the word \"Black\" is used in the context of race, the weight put on\n",
    "# it is higher than when \"Indian\" or \"Asian\" is used instead. \n",
    "\n",
    "print(getToxicity(\"Don't be throwing shade.\"))  # AAVE Negative\n",
    "print(getToxicity(\"Do not make disparaging remarks.\"))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"Stop frontin.\"))  # AAVE Negative\n",
    "print(getToxicity(\"Please stop pretending.\"))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"Why you gotta be salty?\"))  # AAVE Negative\n",
    "print(getToxicity(\"Why are you being bitter?\"))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"They always flexing for no reason.\"))  # AAVE Negative\n",
    "print(getToxicity(\"They always show off unnecessarily.\"))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"You're doing the most right now.\"))  # AAVE Negative\n",
    "print(getToxicity(\"You're overdoing it at the moment.\"))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"Bruh, you wildin'.\"))  # AAVE Negative\n",
    "print(getToxicity(\"You are acting irrationally.\"))  # SAE Negative\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"Well, don’t let your mouth start nothing that your ass can’t stand.\"))\n",
    "print(getToxicity(\"Don't start a fight you can't finish. \"))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"Ain’t no woman got no business floatin’ around without no man.\"))\n",
    "print(getToxicity(\"A woman should be in a relationship with a man. \"))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity(\"That's straight trash\"))\n",
    "print(getToxicity(\"That is completely unacceptable.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7687c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Phrase  \\\n",
      "0                                        What's good?   \n",
      "1                                        How are you?   \n",
      "2                                     Yo fit is fire!   \n",
      "3                            Your outfit looks great!   \n",
      "4                                 Nah, that ain't it.   \n",
      "5                     I disagree, that's not correct.   \n",
      "6                              For real? That's wild.   \n",
      "7                          Really? That's surprising.   \n",
      "8                                      Bet, I'm down.   \n",
      "9                                      Sure, I agree.   \n",
      "10                                      You trippin'.   \n",
      "11                               You're overreacting.   \n",
      "12                                       What's good?   \n",
      "13                                       How are you?   \n",
      "14                                    Yo fit is fire!   \n",
      "15                           Your outfit looks great!   \n",
      "16                                Nah, that ain't it.   \n",
      "17                    I disagree, that's not correct.   \n",
      "18                             For real? That's wild.   \n",
      "19                         Really? That's surprising.   \n",
      "20                                     Bet, I'm down.   \n",
      "21                                     Sure, I agree.   \n",
      "22                                      You trippin'.   \n",
      "23                               You're overreacting.   \n",
      "24                                  Good lookin' out.   \n",
      "25                           Thank you for your help.   \n",
      "26                                   That's a breeze.   \n",
      "27                                  That's very easy.   \n",
      "28                                   That's top-tier.   \n",
      "29                            That's of high quality.   \n",
      "30                                       You cappin'.   \n",
      "31                               I don't believe you.   \n",
      "32                        That's the jam right there!   \n",
      "33                            That song is fantastic!   \n",
      "34                              We out here thriving!   \n",
      "35                We are succeeding in our endeavors!   \n",
      "36                                  She stay winning.   \n",
      "37                          She continues to succeed.   \n",
      "38                           They're keeping it real.   \n",
      "39                          They are being authentic.   \n",
      "40                                   That's on point!   \n",
      "41                              That's exactly right!   \n",
      "42                       Killing it with those moves!   \n",
      "43               Your dance is incredibly impressive!   \n",
      "44                           Don’t be throwing shade.   \n",
      "45                   Do not make disparaging remarks.   \n",
      "46                                      Stop frontin.   \n",
      "47                            Please stop pretending.   \n",
      "48                            Why you gotta be salty?   \n",
      "49                          Why are you being bitter?   \n",
      "50                 They always flexing for no reason.   \n",
      "51                They always show off unnecessarily.   \n",
      "52                   You're doing the most right now.   \n",
      "53                 You're overdoing it at the moment.   \n",
      "54                                 Bruh, you wildin’.   \n",
      "55                       You are acting irrationally.   \n",
      "56  Well, don’t let your mouth start nothing that ...   \n",
      "57                              That's straight trash   \n",
      "\n",
      "    Predicted_Toxicity_Score  Predicted_Toxicity  Actual_Toxicity  \n",
      "0                   0.019603                   0                0  \n",
      "1                   0.018849                   0                0  \n",
      "2                   0.246033                   0                0  \n",
      "3                   0.042657                   0                0  \n",
      "4                   0.012692                   0                0  \n",
      "5                   0.021196                   0                0  \n",
      "6                   0.107399                   0                0  \n",
      "7                   0.012629                   0                0  \n",
      "8                   0.028031                   0                0  \n",
      "9                   0.008545                   0                0  \n",
      "10                  0.199864                   0                0  \n",
      "11                  0.098288                   0                0  \n",
      "12                  0.019603                   0                0  \n",
      "13                  0.018849                   0                0  \n",
      "14                  0.246033                   0                0  \n",
      "15                  0.042657                   0                0  \n",
      "16                  0.012692                   0                0  \n",
      "17                  0.021196                   0                0  \n",
      "18                  0.107399                   0                0  \n",
      "19                  0.012629                   0                0  \n",
      "20                  0.028031                   0                0  \n",
      "21                  0.008545                   0                0  \n",
      "22                  0.199864                   0                0  \n",
      "23                  0.098288                   0                0  \n",
      "24                  0.018095                   0                0  \n",
      "25                  0.010995                   0                0  \n",
      "26                  0.035927                   0                0  \n",
      "27                  0.016713                   0                0  \n",
      "28                  0.018849                   0                0  \n",
      "29                  0.016839                   0                0  \n",
      "30                  0.144296                   0                0  \n",
      "31                  0.199399                   0                0  \n",
      "32                  0.052058                   0                0  \n",
      "33                  0.023671                   0                0  \n",
      "34                  0.031213                   0                0  \n",
      "35                  0.025557                   0                0  \n",
      "36                  0.014262                   0                0  \n",
      "37                  0.018598                   0                0  \n",
      "38                  0.015645                   0                0  \n",
      "39                  0.022139                   0                0  \n",
      "40                  0.010430                   0                0  \n",
      "41                  0.011372                   0                0  \n",
      "42                  0.440214                   0                0  \n",
      "43                  0.023318                   0                0  \n",
      "44                  0.052058                   0                0  \n",
      "45                  0.107833                   0                0  \n",
      "46                  0.055274                   0                0  \n",
      "47                  0.118262                   0                0  \n",
      "48                  0.160431                   0                0  \n",
      "49                  0.101759                   0                0  \n",
      "50                  0.047605                   0                0  \n",
      "51                  0.034984                   0                0  \n",
      "52                  0.023553                   0                0  \n",
      "53                  0.031213                   0                0  \n",
      "54                  0.051069                   0                0  \n",
      "55                  0.280878                   0                0  \n",
      "56                  0.829959                   1                1  \n",
      "57                  0.228937                   0                1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data including phrases and their API predicted scores\n",
    "data = [\n",
    "    {\"Phrase\": \"What's good?\", \"Predicted_Toxicity_Score\": 0.019603057},\n",
    "    {\"Phrase\": \"How are you?\", \"Predicted_Toxicity_Score\": 0.018849092},\n",
    "    {\"Phrase\": \"Yo fit is fire!\", \"Predicted_Toxicity_Score\": 0.24603334},\n",
    "    {\"Phrase\": \"Your outfit looks great!\", \"Predicted_Toxicity_Score\": 0.042657252},\n",
    "    {\"Phrase\": \"Nah, that ain't it.\", \"Predicted_Toxicity_Score\": 0.012691722},\n",
    "    {\"Phrase\": \"I disagree, that's not correct.\", \"Predicted_Toxicity_Score\": 0.021196328},\n",
    "    {\"Phrase\": \"For real? That's wild.\", \"Predicted_Toxicity_Score\": 0.10739898},\n",
    "    {\"Phrase\": \"Really? That's surprising.\", \"Predicted_Toxicity_Score\": 0.0126288915},\n",
    "    {\"Phrase\": \"Bet, I'm down.\", \"Predicted_Toxicity_Score\": 0.028031485},\n",
    "    {\"Phrase\": \"Sure, I agree.\", \"Predicted_Toxicity_Score\": 0.008544922},\n",
    "    {\"Phrase\": \"You trippin'.\", \"Predicted_Toxicity_Score\": 0.19986437},\n",
    "    {\"Phrase\": \"You're overreacting.\", \"Predicted_Toxicity_Score\": 0.09828771},\n",
    "    {\"Phrase\": \"What's good?\", \"Predicted_Toxicity_Score\": 0.019603057},\n",
    "    {\"Phrase\": \"How are you?\", \"Predicted_Toxicity_Score\": 0.018849092},\n",
    "    {\"Phrase\": \"Yo fit is fire!\", \"Predicted_Toxicity_Score\": 0.24603334},\n",
    "    {\"Phrase\": \"Your outfit looks great!\", \"Predicted_Toxicity_Score\": 0.042657252},\n",
    "    {\"Phrase\": \"Nah, that ain't it.\", \"Predicted_Toxicity_Score\": 0.012691722},\n",
    "    {\"Phrase\": \"I disagree, that's not correct.\", \"Predicted_Toxicity_Score\": 0.021196328},\n",
    "    {\"Phrase\": \"For real? That's wild.\", \"Predicted_Toxicity_Score\": 0.10739898},\n",
    "    {\"Phrase\": \"Really? That's surprising.\", \"Predicted_Toxicity_Score\": 0.0126288915},\n",
    "    {\"Phrase\": \"Bet, I'm down.\", \"Predicted_Toxicity_Score\": 0.028031485},\n",
    "    {\"Phrase\": \"Sure, I agree.\", \"Predicted_Toxicity_Score\": 0.008544922},\n",
    "    {\"Phrase\": \"You trippin'.\", \"Predicted_Toxicity_Score\": 0.19986437},\n",
    "    {\"Phrase\": \"You're overreacting.\", \"Predicted_Toxicity_Score\": 0.09828771},\n",
    "    {\"Phrase\": \"Good lookin' out.\", \"Predicted_Toxicity_Score\": 0.018095128},\n",
    "    {\"Phrase\": \"Thank you for your help.\", \"Predicted_Toxicity_Score\": 0.010995304},\n",
    "    {\"Phrase\": \"That's a breeze.\", \"Predicted_Toxicity_Score\": 0.03592727},\n",
    "    {\"Phrase\": \"That's very easy.\", \"Predicted_Toxicity_Score\": 0.016712861},\n",
    "    {\"Phrase\": \"That's top-tier.\", \"Predicted_Toxicity_Score\": 0.018849092},\n",
    "    {\"Phrase\": \"That's of high quality.\", \"Predicted_Toxicity_Score\": 0.016838523},\n",
    "    {\"Phrase\": \"You cappin'.\", \"Predicted_Toxicity_Score\": 0.14429577},\n",
    "    {\"Phrase\": \"I don't believe you.\", \"Predicted_Toxicity_Score\": 0.19939905},\n",
    "    {\"Phrase\": \"That's the jam right there!\", \"Predicted_Toxicity_Score\": 0.05205809},\n",
    "    {\"Phrase\": \"That song is fantastic!\", \"Predicted_Toxicity_Score\": 0.023671126},\n",
    "    {\"Phrase\": \"We out here thriving!\", \"Predicted_Toxicity_Score\": 0.031213367},\n",
    "    {\"Phrase\": \"We are succeeding in our endeavors!\", \"Predicted_Toxicity_Score\": 0.025556687},\n",
    "    {\"Phrase\": \"She stay winning.\", \"Predicted_Toxicity_Score\": 0.01426248},\n",
    "    {\"Phrase\": \"She continues to succeed.\", \"Predicted_Toxicity_Score\": 0.01859777},\n",
    "    {\"Phrase\": \"They're keeping it real.\", \"Predicted_Toxicity_Score\": 0.015644746},\n",
    "    {\"Phrase\": \"They are being authentic.\", \"Predicted_Toxicity_Score\": 0.022139108},\n",
    "    {\"Phrase\": \"That's on point!\", \"Predicted_Toxicity_Score\": 0.010429831},\n",
    "    {\"Phrase\": \"That's exactly right!\", \"Predicted_Toxicity_Score\": 0.011372286},\n",
    "    {\"Phrase\": \"Killing it with those moves!\", \"Predicted_Toxicity_Score\": 0.4402136},\n",
    "    {\"Phrase\": \"Your dance is incredibly impressive!\", \"Predicted_Toxicity_Score\": 0.023317585},\n",
    "    {\"Phrase\": \"Don’t be throwing shade.\", \"Predicted_Toxicity_Score\": 0.05205809},\n",
    "    {\"Phrase\": \"Do not make disparaging remarks.\", \"Predicted_Toxicity_Score\": 0.10783285},\n",
    "    {\"Phrase\": \"Stop frontin.\", \"Predicted_Toxicity_Score\": 0.055274},\n",
    "    {\"Phrase\": \"Please stop pretending.\", \"Predicted_Toxicity_Score\": 0.1182615},\n",
    "    {\"Phrase\": \"Why you gotta be salty?\", \"Predicted_Toxicity_Score\": 0.16043124},\n",
    "    {\"Phrase\": \"Why are you being bitter?\", \"Predicted_Toxicity_Score\": 0.10175867},\n",
    "    {\"Phrase\": \"They always flexing for no reason.\", \"Predicted_Toxicity_Score\": 0.04760506},\n",
    "    {\"Phrase\": \"They always show off unnecessarily.\", \"Predicted_Toxicity_Score\": 0.034984488},\n",
    "    {\"Phrase\": \"You're doing the most right now.\", \"Predicted_Toxicity_Score\": 0.023553278},\n",
    "    {\"Phrase\": \"You're overdoing it at the moment.\", \"Predicted_Toxicity_Score\": 0.031213367},\n",
    "    {\"Phrase\": \"Bruh, you wildin’.\", \"Predicted_Toxicity_Score\": 0.051068526},\n",
    "    {\"Phrase\": \"You are acting irrationally.\", \"Predicted_Toxicity_Score\": 0.28087774}, \n",
    "    {\"Phrase\": \"Well, don’t let your mouth start nothing that your ass can’t stand.\", \"Predicted_Toxicity_Score\": 0.8299589},\n",
    "{\"Phrase\": \"That's straight trash\", \"Predicted_Toxicity_Score\": 0.2289369}]\n",
    "\n",
    "# Make the list of dictionaries to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Make Predicted Toxicity Scores to binary (1 for Toxic, 0 for Non-Toxic)\n",
    "df['Predicted_Toxicity'] = (df['Predicted_Toxicity_Score'] > 0.5).astype(int)\n",
    "\n",
    "# all are labeled as Non-Toxic for demonstration as they are all below 0.5\n",
    "df['Actual_Toxicity'] = 0 # All these examples are labeled Non-Toxic\n",
    "\n",
    "\n",
    "toxic_indices = df[df['Phrase'].isin([\"That's straight trash\", \"Well, don’t let your mouth start nothing that your ass can’t stand.\"])].index\n",
    "df.loc[toxic_indices, 'Actual_Toxicity'] = 1\n",
    "\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"predicted_vs_actual.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e365e7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Actual Toxicity Values: [0 1]\n",
      "Unique Predicted Toxicity Values: [0 1]\n",
      "Percent of toxic phrases correctly identified (TP rate): 50.0\n",
      "Percent of non-toxic phrases correctly identified (TN rate): 100.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictedVsActualData = pd.read_csv(\"predicted_vs_actual.csv\")\n",
    "\n",
    "# Check unique values in the columns for confirmation\n",
    "print(\"Unique Actual Toxicity Values:\", predictedVsActualData['Actual_Toxicity'].unique())\n",
    "print(\"Unique Predicted Toxicity Values:\", predictedVsActualData['Predicted_Toxicity'].unique())\n",
    "\n",
    "# Define the function for class-wise accuracy calculation\n",
    "def class_wise_acc(y_actual, y_predicted):\n",
    "    total_p = 0\n",
    "    total_n = 0\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    for i in range(len(y_predicted)):\n",
    "        if y_actual[i] == 1:\n",
    "            total_p += 1\n",
    "            if y_actual[i] == y_predicted[i]:\n",
    "                TP += 1\n",
    "        elif y_actual[i] == 0:\n",
    "            total_n += 1\n",
    "            if y_actual[i] == y_predicted[i]:\n",
    "                TN += 1\n",
    "\n",
    "    TP_rate = TP / total_p if total_p else 0  # Don't want division by zero if no positive cases\n",
    "    TN_rate = TN / total_n if total_n else 1  \n",
    "\n",
    "    return (TP_rate, TN_rate)\n",
    "\n",
    "\n",
    "accuracyToxic, accuracyNonT = class_wise_acc(predictedVsActualData['Actual_Toxicity'], predictedVsActualData['Predicted_Toxicity'])\n",
    "\n",
    "print(\"Percent of toxic phrases correctly identified (TP rate):\", accuracyToxic * 100)\n",
    "print(\"Percent of non-toxic phrases correctly identified (TN rate):\", accuracyNonT * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec0daab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Phrase', 'Predicted_Toxicity_Score', 'Predicted_Toxicity',\n",
      "       'Actual_Toxicity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "predictedVsActualData = pd.read_csv(\"predicted_vs_actual.csv\")\n",
    "\n",
    "# Print out column names to verify we're having right columns\n",
    "print(predictedVsActualData.columns)\n",
    "\n",
    "# Actual Toxicity exists\n",
    "if 'Actual Toxicity' not in predictedVsActualData.columns:\n",
    "    predictedVsActualData.rename(columns={'existing_column_name': 'Actual Toxicity'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6671977",
   "metadata": {},
   "source": [
    "Insights -- \n",
    "\n",
    "Based on the output I've provided, it appears that my actual and predicted toxicity labels are 0 and 1 -- This shows that the model is predicting both non-toxic (0) and toxic (1) labels. Unlike the actual labels, the model does not uniformly predict all comments as non-toxic; it identifies some as potentially toxic.\n",
    "\n",
    "As a result, my model has achieved a 100% True Negative Rate (TN rate), meaning it correctly identified all samples as non-toxic, which matches the actual data. However, the True Positive Rate (TP rate) is 50% because there were some toxic samples, but it predicted only half of them correctly.\n",
    "\n",
    "I randomly sampled AAVE Negative phrases, for which all of them came out as less than the threshold of 0.5. This \n",
    "model is also experiencing word bias — whenever the word \"Black\" is used in the context of race, the weight put on it is higher than when \"Indian\" or \"Asian\" is used instead. This example proves itself in the phrase \"He was a Black guy\". Substituting \"Black\" for \"Indian\", the toxicity went from 0.36 to 0.16. \n",
    "\n",
    "My hypothesis is supported, as the overt vulgar usage of \"ass\" was properly determined as a toxic statement, while the other statement was discarded for seeming word-weight reasons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bdd874",
   "metadata": {},
   "source": [
    "Not just that, I've learnt to test AI mdoels, the datasets we use need to reflect real-world communication — you can't analyze language just mathematically. This means we'd have to look at diverse, cultural references. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e906d80",
   "metadata": {},
   "source": [
    "For findings, Perspective API had a high accuracy rate in identifying non-toxic comments (100% TN rate) but was less effective at correctly identifying toxic comments, achieving only a 50% TP rate. This partial success suggests that while the model is proficient at recognizing clear-cut cases of non-toxicity, its limited in its ability to detect toxic statements.\n",
    "\n",
    "It was somewhat surprising to see such a disparity in the detection rates between overt and subtle toxicities. This goes into limitations/biases of the algorithm — like I said before, linguistic cues (context) seems to be a limitation and overt, crude language is the only big giveaway for this model.  \n",
    "\n",
    "More on biases, the model's training dataset likely includes more examples of explicit toxicity than subtle, context-dependent toxicity. \n",
    "Also, The API may not grasp cultural nuances when it comes to subtle toxicity — the added factor that this is African American vernacular, vernacular derived historically from underprivileged communities that may be very different than the environment this model is trained in. \n",
    "\n",
    "When it comes to theories on the results, \n",
    "the model might be tuned to detect strong indicators of toxicity such as profanity and direct insults, which are easier to label and more uniformly agreed upon in training data. Therefore, the algorithms would have an easier time at pattern recognition involving explicit markers of toxicity than those that require contextual understanding.\n",
    "\n",
    "Questions and Further Investigation:\n",
    "\n",
    "- How can we improve training datasets so that subtle toxicity makes headway in training?\n",
    "- What ways can cultural biases in models be addressed, and historical disadvantages of communities be brought to the limelight in their training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d083b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
